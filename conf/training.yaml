defaults:
  - environment: pursuit_evasion
  - training: default
  - scenario: ppo_pursuer_vs_dqn_evader
  - _self_

# Experiment settings
experiment_name: "drone_pursuit_evasion"
seed: 42
device: "auto"  # auto, cpu, cuda

# Wandb settings
wandb:
  project: "drone-pursuit-evasion"
  entity: null
  mode: "online"  # online, offline, disabled
  tags: []
  notes: ""

# Paths
paths:
  weights_dir: "weights"
  logs_dir: "logs"
  data_dir: "data"

# Hydra job settings
hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job:
    chdir: true

training:
  total_timesteps: 10000000
  save_interval: 5000
  evaluate_interval: 10000
  eval_episodes: 3
  save_best_model: true
  save_final_model: true
  log_interval: 100
  resume_from: null 